{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Importance Analysis for Traffic Severity\n",
        "\n",
        "This notebook identifies which parameters contribute most to traffic accident severity using various feature importance techniques.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style for better visualizations\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load and Explore Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the data\n",
        "df = pd.read_csv('../data/processed/sample_df.csv')\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"\\nColumns: {list(df.columns)}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check severity distribution\n",
        "print(\"Severity distribution:\")\n",
        "print(df['Severity'].value_counts().sort_index())\n",
        "print(f\"\\nSeverity distribution percentage:\")\n",
        "print(df['Severity'].value_counts(normalize=True).sort_index() * 100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select numerical features that might be relevant\n",
        "numerical_features = [\n",
        "    'Temperature(F)', 'Wind_Chill(F)', 'Humidity(%)', 'Pressure(in)', \n",
        "    'Visibility(mi)', 'Wind_Speed(mph)', 'Precipitation(in)', 'Distance(mi)'\n",
        "]\n",
        "\n",
        "# Select categorical features\n",
        "categorical_features = [\n",
        "    'Weather_Condition', 'Sunrise_Sunset', 'Civil_Twilight', \n",
        "    'Nautical_Twilight', 'Astronomical_Twilight'\n",
        "]\n",
        "\n",
        "# Binary features\n",
        "binary_features = [\n",
        "    'Amenity', 'Bump', 'Crossing', 'Give_Way', 'Junction', \n",
        "    'No_Exit', 'Railway', 'Roundabout', 'Station', 'Stop', \n",
        "    'Traffic_Calming', 'Traffic_Signal', 'Turning_Loop'\n",
        "]\n",
        "\n",
        "# Combine all potential features\n",
        "all_features = numerical_features + categorical_features + binary_features\n",
        "\n",
        "# Check which features exist in the dataset\n",
        "available_features = [f for f in all_features if f in df.columns]\n",
        "print(f\"Available features: {len(available_features)} out of {len(all_features)}\")\n",
        "print(f\"\\nMissing features: {set(all_features) - set(available_features)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare the dataset\n",
        "# Start with numerical features\n",
        "feature_df = df[available_features + ['Severity']].copy()\n",
        "\n",
        "# Handle missing values - fill numerical with median, categorical with mode\n",
        "for col in feature_df.columns:\n",
        "    if col == 'Severity':\n",
        "        continue\n",
        "    if feature_df[col].dtype in ['int64', 'float64']:\n",
        "        feature_df[col].fillna(feature_df[col].median(), inplace=True)\n",
        "    else:\n",
        "        feature_df[col].fillna(feature_df[col].mode()[0] if len(feature_df[col].mode()) > 0 else 'Unknown', inplace=True)\n",
        "\n",
        "# Encode categorical variables\n",
        "le_dict = {}\n",
        "for col in categorical_features:\n",
        "    if col in feature_df.columns:\n",
        "        le = LabelEncoder()\n",
        "        feature_df[col] = le.fit_transform(feature_df[col].astype(str))\n",
        "        le_dict[col] = le\n",
        "\n",
        "# Convert binary features to numeric if they're not already\n",
        "for col in binary_features:\n",
        "    if col in feature_df.columns:\n",
        "        if feature_df[col].dtype == 'object':\n",
        "            feature_df[col] = feature_df[col].astype(int)\n",
        "\n",
        "print(f\"Final dataset shape: {feature_df.shape}\")\n",
        "print(f\"Missing values: {feature_df.isnull().sum().sum()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Correlation Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate correlation with severity\n",
        "correlations = feature_df.corr()['Severity'].sort_values(ascending=False)\n",
        "correlations = correlations.drop('Severity')  # Remove self-correlation\n",
        "\n",
        "print(\"Correlation with Severity (sorted by absolute value):\")\n",
        "print(\"=\" * 60)\n",
        "for feature, corr in correlations.items():\n",
        "    print(f\"{feature:30s}: {corr:7.4f}\")\n",
        "\n",
        "# Visualize correlations\n",
        "plt.figure(figsize=(10, 8))\n",
        "correlations_sorted = correlations.reindex(correlations.abs().sort_values(ascending=False).index)\n",
        "colors = ['red' if x < 0 else 'green' for x in correlations_sorted.values]\n",
        "plt.barh(range(len(correlations_sorted)), correlations_sorted.values, color=colors)\n",
        "plt.yticks(range(len(correlations_sorted)), correlations_sorted.index)\n",
        "plt.xlabel('Correlation with Severity')\n",
        "plt.title('Feature Correlations with Traffic Severity')\n",
        "plt.axvline(x=0, color='black', linestyle='--', linewidth=0.8)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.5. Visualizing How Parameters Affect Severity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive visualizations showing how parameters affect severity\n",
        "# Focus on top numerical features\n",
        "top_numerical = [f for f in numerical_features if f in df.columns][:6]  # Top 6 numerical features\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, feature in enumerate(top_numerical):\n",
        "    # Prepare data for each severity level\n",
        "    severity_levels = sorted(df['Severity'].dropna().unique())\n",
        "    data_by_severity = [df[df['Severity'] == sev][feature].dropna() for sev in severity_levels]\n",
        "    \n",
        "    # Create box plot\n",
        "    bp = axes[idx].boxplot(data_by_severity, labels=[f'Severity {int(s)}' for s in severity_levels], \n",
        "                          patch_artist=True, showmeans=True)\n",
        "    \n",
        "    # Color the boxes\n",
        "    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A']\n",
        "    for patch, color in zip(bp['boxes'], colors[:len(bp['boxes'])]):\n",
        "        patch.set_facecolor(color)\n",
        "        patch.set_alpha(0.7)\n",
        "    \n",
        "    axes[idx].set_title(f'{feature} by Severity Level', fontsize=12, fontweight='bold')\n",
        "    axes[idx].set_xlabel('Severity Level')\n",
        "    axes[idx].set_ylabel(feature)\n",
        "    axes[idx].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.suptitle('Distribution of Numerical Parameters by Severity Level', fontsize=16, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Violin plots for better distribution visualization\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, feature in enumerate(top_numerical):\n",
        "    # Prepare data\n",
        "    plot_data = []\n",
        "    labels = []\n",
        "    for severity in sorted(df['Severity'].dropna().unique()):\n",
        "        data = df[df['Severity'] == severity][feature].dropna()\n",
        "        if len(data) > 0:\n",
        "            plot_data.append(data)\n",
        "            labels.append(f'Severity {int(severity)}')\n",
        "    \n",
        "    # Create violin plot\n",
        "    parts = axes[idx].violinplot(plot_data, positions=range(len(plot_data)), \n",
        "                                  showmeans=True, showmedians=True)\n",
        "    \n",
        "    # Customize colors\n",
        "    for pc, color in zip(parts['bodies'], colors[:len(parts['bodies'])]):\n",
        "        pc.set_facecolor(color)\n",
        "        pc.set_alpha(0.7)\n",
        "    \n",
        "    axes[idx].set_xticks(range(len(labels)))\n",
        "    axes[idx].set_xticklabels(labels)\n",
        "    axes[idx].set_title(f'{feature} Distribution by Severity', fontsize=12, fontweight='bold')\n",
        "    axes[idx].set_xlabel('Severity Level')\n",
        "    axes[idx].set_ylabel(feature)\n",
        "    axes[idx].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.suptitle('Parameter Distributions by Severity (Violin Plots)', fontsize=16, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Average parameter values by severity level\n",
        "severity_levels = sorted(df['Severity'].dropna().unique())\n",
        "avg_values = pd.DataFrame(index=severity_levels)\n",
        "\n",
        "for feature in top_numerical:\n",
        "    avg_values[feature] = [df[df['Severity'] == sev][feature].mean() for sev in severity_levels]\n",
        "\n",
        "# Normalize for better comparison (0-1 scale)\n",
        "avg_values_norm = avg_values.copy()\n",
        "for col in avg_values_norm.columns:\n",
        "    col_min = avg_values_norm[col].min()\n",
        "    col_max = avg_values_norm[col].max()\n",
        "    if col_max - col_min > 0:\n",
        "        avg_values_norm[col] = (avg_values_norm[col] - col_min) / (col_max - col_min)\n",
        "\n",
        "# Heatmap\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
        "\n",
        "# Raw averages\n",
        "sns.heatmap(avg_values.T, annot=True, fmt='.2f', cmap='YlOrRd', ax=ax1, \n",
        "            cbar_kws={'label': 'Average Value'}, linewidths=0.5)\n",
        "ax1.set_title('Average Parameter Values by Severity Level', fontsize=14, fontweight='bold')\n",
        "ax1.set_xlabel('Severity Level')\n",
        "ax1.set_ylabel('Parameter')\n",
        "\n",
        "# Normalized averages\n",
        "sns.heatmap(avg_values_norm.T, annot=True, fmt='.3f', cmap='YlOrRd', ax=ax2,\n",
        "            cbar_kws={'label': 'Normalized Value (0-1)'}, linewidths=0.5)\n",
        "ax2.set_title('Normalized Average Values (for comparison)', fontsize=14, fontweight='bold')\n",
        "ax2.set_xlabel('Severity Level')\n",
        "ax2.set_ylabel('Parameter')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bar charts showing average values by severity\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, feature in enumerate(top_numerical):\n",
        "    severity_means = []\n",
        "    severity_stds = []\n",
        "    severity_labels = []\n",
        "    \n",
        "    for severity in sorted(df['Severity'].dropna().unique()):\n",
        "        data = df[df['Severity'] == severity][feature].dropna()\n",
        "        if len(data) > 0:\n",
        "            severity_means.append(data.mean())\n",
        "            severity_stds.append(data.std())\n",
        "            severity_labels.append(f'Severity {int(severity)}')\n",
        "    \n",
        "    x_pos = np.arange(len(severity_labels))\n",
        "    bars = axes[idx].bar(x_pos, severity_means, yerr=severity_stds, \n",
        "                         capsize=5, alpha=0.7, color=colors[:len(severity_labels)])\n",
        "    axes[idx].set_xlabel('Severity Level')\n",
        "    axes[idx].set_ylabel(f'Average {feature}')\n",
        "    axes[idx].set_title(f'Average {feature} by Severity', fontsize=12, fontweight='bold')\n",
        "    axes[idx].set_xticks(x_pos)\n",
        "    axes[idx].set_xticklabels(severity_labels)\n",
        "    axes[idx].grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    # Add value labels on bars\n",
        "    for bar, mean_val in zip(bars, severity_means):\n",
        "        height = bar.get_height()\n",
        "        axes[idx].text(bar.get_x() + bar.get_width()/2., height,\n",
        "                      f'{mean_val:.2f}', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "plt.suptitle('Average Parameter Values by Severity Level (with Error Bars)', \n",
        "             fontsize=16, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scatter plots showing relationship between parameters and severity\n",
        "# Select top 4 most important numerical features for pairwise comparison\n",
        "if len(top_numerical) >= 2:\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    # Create scatter plots for top 4 features\n",
        "    top_4_features = top_numerical[:4]\n",
        "    \n",
        "    for idx, feature in enumerate(top_4_features):\n",
        "        scatter_data = df[[feature, 'Severity']].dropna()\n",
        "        \n",
        "        # Create scatter plot with color coding by severity\n",
        "        scatter = axes[idx].scatter(scatter_data[feature], scatter_data['Severity'], \n",
        "                                   c=scatter_data['Severity'], cmap='RdYlGn_r', \n",
        "                                   alpha=0.5, s=20, edgecolors='black', linewidth=0.5)\n",
        "        \n",
        "        axes[idx].set_xlabel(feature, fontsize=11)\n",
        "        axes[idx].set_ylabel('Severity Level', fontsize=11)\n",
        "        axes[idx].set_title(f'{feature} vs Severity', fontsize=12, fontweight='bold')\n",
        "        axes[idx].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Add trend line\n",
        "        z = np.polyfit(scatter_data[feature], scatter_data['Severity'], 1)\n",
        "        p = np.poly1d(z)\n",
        "        axes[idx].plot(scatter_data[feature].sort_values(), \n",
        "                      p(scatter_data[feature].sort_values()), \n",
        "                      \"r--\", alpha=0.8, linewidth=2, label='Trend Line')\n",
        "        axes[idx].legend()\n",
        "        \n",
        "        plt.colorbar(scatter, ax=axes[idx], label='Severity Level')\n",
        "    \n",
        "    plt.suptitle('Parameter Values vs Severity Level (Scatter Plots)', \n",
        "                 fontsize=16, fontweight='bold', y=0.995)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Categorical features impact on severity\n",
        "categorical_available = [f for f in categorical_features if f in df.columns]\n",
        "\n",
        "if len(categorical_available) > 0:\n",
        "    # Take first 4 categorical features\n",
        "    top_categorical = categorical_available[:4]\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 2, figsize=(18, 14))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    for idx, feature in enumerate(top_categorical):\n",
        "        # Calculate severity distribution for each category\n",
        "        category_severity = df.groupby([feature, 'Severity']).size().unstack(fill_value=0)\n",
        "        category_severity_pct = category_severity.div(category_severity.sum(axis=1), axis=0) * 100\n",
        "        \n",
        "        # Plot stacked bar chart\n",
        "        category_severity_pct.plot(kind='bar', stacked=True, ax=axes[idx], \n",
        "                                   color=colors[:len(category_severity_pct.columns)], \n",
        "                                   alpha=0.8, width=0.8)\n",
        "        \n",
        "        axes[idx].set_title(f'{feature} Impact on Severity', fontsize=12, fontweight='bold')\n",
        "        axes[idx].set_xlabel(feature)\n",
        "        axes[idx].set_ylabel('Percentage (%)')\n",
        "        axes[idx].legend(title='Severity', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "        axes[idx].tick_params(axis='x', rotation=45)\n",
        "        axes[idx].grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    plt.suptitle('Categorical Parameters Impact on Severity Distribution', \n",
        "                 fontsize=16, fontweight='bold', y=0.995)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Binary features impact on severity\n",
        "binary_available = [f for f in binary_features if f in df.columns]\n",
        "\n",
        "if len(binary_available) > 0:\n",
        "    # Take top 6 binary features\n",
        "    top_binary = binary_available[:6]\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    for idx, feature in enumerate(top_binary):\n",
        "        # Calculate average severity for each binary value\n",
        "        binary_severity = df.groupby(feature)['Severity'].agg(['mean', 'std', 'count']).reset_index()\n",
        "        binary_severity[feature] = binary_severity[feature].astype(str)\n",
        "        \n",
        "        # Create bar plot\n",
        "        bars = axes[idx].bar(binary_severity[feature], binary_severity['mean'], \n",
        "                            yerr=binary_severity['std'], capsize=5, \n",
        "                            color=colors[:len(binary_severity)], alpha=0.7)\n",
        "        \n",
        "        axes[idx].set_title(f'{feature} Impact on Severity', fontsize=11, fontweight='bold')\n",
        "        axes[idx].set_xlabel(f'{feature} (0=No, 1=Yes)')\n",
        "        axes[idx].set_ylabel('Average Severity')\n",
        "        axes[idx].grid(True, alpha=0.3, axis='y')\n",
        "        \n",
        "        # Add count labels\n",
        "        for bar, count in zip(bars, binary_severity['count']):\n",
        "            height = bar.get_height()\n",
        "            axes[idx].text(bar.get_x() + bar.get_width()/2., height,\n",
        "                          f'n={count}', ha='center', va='bottom', fontsize=8)\n",
        "    \n",
        "    plt.suptitle('Binary Features Impact on Average Severity', \n",
        "                 fontsize=16, fontweight='bold', y=1.02)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Statistical summary: How parameters differ across severity levels\n",
        "print(\"=\" * 80)\n",
        "print(\"STATISTICAL SUMMARY: Parameter Differences Across Severity Levels\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for feature in top_numerical[:5]:  # Top 5 features\n",
        "    print(f\"\\n{feature}:\")\n",
        "    print(\"-\" * 60)\n",
        "    severity_stats = df.groupby('Severity')[feature].agg(['mean', 'median', 'std', 'min', 'max'])\n",
        "    print(severity_stats.round(2))\n",
        "    \n",
        "    # Calculate difference between highest and lowest severity\n",
        "    if len(severity_stats) > 1:\n",
        "        mean_diff = severity_stats['mean'].max() - severity_stats['mean'].min()\n",
        "        pct_diff = (mean_diff / severity_stats['mean'].min()) * 100 if severity_stats['mean'].min() != 0 else 0\n",
        "        print(f\"\\n  Mean difference (max-min): {mean_diff:.2f} ({pct_diff:.1f}% change)\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pairwise comparison: Show how top 2 parameters interact with severity\n",
        "if len(top_numerical) >= 2:\n",
        "    top_2_features = top_numerical[:2]\n",
        "    \n",
        "    fig = plt.figure(figsize=(16, 6))\n",
        "    \n",
        "    # 3D-like visualization using scatter with size/color\n",
        "    ax1 = fig.add_subplot(121)\n",
        "    scatter_data = df[top_2_features + ['Severity']].dropna()\n",
        "    \n",
        "    scatter = ax1.scatter(scatter_data[top_2_features[0]], \n",
        "                         scatter_data[top_2_features[1]], \n",
        "                         c=scatter_data['Severity'], \n",
        "                         s=50, alpha=0.6, cmap='RdYlGn_r', \n",
        "                         edgecolors='black', linewidth=0.3)\n",
        "    \n",
        "    ax1.set_xlabel(top_2_features[0], fontsize=11)\n",
        "    ax1.set_ylabel(top_2_features[1], fontsize=11)\n",
        "    ax1.set_title(f'{top_2_features[0]} vs {top_2_features[1]} (colored by Severity)', \n",
        "                 fontsize=12, fontweight='bold')\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    plt.colorbar(scatter, ax=ax1, label='Severity Level')\n",
        "    \n",
        "    # Hexbin plot for density\n",
        "    ax2 = fig.add_subplot(122)\n",
        "    hb = ax2.hexbin(scatter_data[top_2_features[0]], \n",
        "                   scatter_data[top_2_features[1]], \n",
        "                   C=scatter_data['Severity'], \n",
        "                   gridsize=20, cmap='RdYlGn_r', reduce_C_function=np.mean)\n",
        "    \n",
        "    ax2.set_xlabel(top_2_features[0], fontsize=11)\n",
        "    ax2.set_ylabel(top_2_features[1], fontsize=11)\n",
        "    ax2.set_title(f'Density Plot: {top_2_features[0]} vs {top_2_features[1]}', \n",
        "                 fontsize=12, fontweight='bold')\n",
        "    plt.colorbar(hb, ax=ax2, label='Average Severity')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Key Insights from Parameter-Severity Visualizations\n",
        "\n",
        "The graphs above show:\n",
        "- **Box/Violin Plots**: Distribution shapes and outliers for each severity level\n",
        "- **Heatmaps**: Quick comparison of average values across severity levels\n",
        "- **Bar Charts**: Clear average values with error bars showing variability\n",
        "- **Scatter Plots**: Individual data points and trends\n",
        "- **Categorical Analysis**: How categorical features affect severity distribution\n",
        "- **Binary Features**: Impact of presence/absence of road features on severity\n",
        "\n",
        "These visualizations help identify which parameters have the strongest relationship with accident severity.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Random Forest Feature Importance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for modeling\n",
        "X = feature_df.drop('Severity', axis=1)\n",
        "y = feature_df['Severity']\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=38, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Training set: {X_train.shape[0]} samples\")\n",
        "print(f\"Test set: {X_test.shape[0]} samples\")\n",
        "\n",
        "# Train Random Forest\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=38, n_jobs=-1)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importances\n",
        "feature_importance_rf = pd.DataFrame({\n",
        "    'feature': X.columns,\n",
        "    'importance': rf_model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"\\nRandom Forest Feature Importance:\")\n",
        "print(\"=\" * 60)\n",
        "for idx, row in feature_importance_rf.iterrows():\n",
        "    print(f\"{row['feature']:30s}: {row['importance']:7.4f}\")\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.barh(range(len(feature_importance_rf)), feature_importance_rf['importance'].values)\n",
        "plt.yticks(range(len(feature_importance_rf)), feature_importance_rf['feature'].values)\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.title('Random Forest Feature Importance for Traffic Severity')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate model\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "print(f\"\\nRandom Forest Accuracy: {accuracy_rf:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_rf))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Gradient Boosting Feature Importance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Gradient Boosting\n",
        "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=38)\n",
        "gb_model.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importances\n",
        "feature_importance_gb = pd.DataFrame({\n",
        "    'feature': X.columns,\n",
        "    'importance': gb_model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"Gradient Boosting Feature Importance:\")\n",
        "print(\"=\" * 60)\n",
        "for idx, row in feature_importance_gb.iterrows():\n",
        "    print(f\"{row['feature']:30s}: {row['importance']:7.4f}\")\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.barh(range(len(feature_importance_gb)), feature_importance_gb['importance'].values, color='orange')\n",
        "plt.yticks(range(len(feature_importance_gb)), feature_importance_gb['feature'].values)\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.title('Gradient Boosting Feature Importance for Traffic Severity')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate model\n",
        "y_pred_gb = gb_model.predict(X_test)\n",
        "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
        "print(f\"\\nGradient Boosting Accuracy: {accuracy_gb:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_gb))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Logistic Regression Coefficients\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scale features for logistic regression\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression (for multi-class, we'll use one-vs-rest)\n",
        "lr_model = LogisticRegression(max_iter=1000, random_state=38, multi_class='ovr')\n",
        "lr_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Get average absolute coefficients across all classes\n",
        "coef_abs = np.abs(lr_model.coef_).mean(axis=0)\n",
        "feature_importance_lr = pd.DataFrame({\n",
        "    'feature': X.columns,\n",
        "    'coefficient': coef_abs\n",
        "}).sort_values('coefficient', ascending=False)\n",
        "\n",
        "print(\"Logistic Regression Feature Importance (Average Absolute Coefficients):\")\n",
        "print(\"=\" * 60)\n",
        "for idx, row in feature_importance_lr.iterrows():\n",
        "    print(f\"{row['feature']:30s}: {row['coefficient']:7.4f}\")\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.barh(range(len(feature_importance_lr)), feature_importance_lr['coefficient'].values, color='purple')\n",
        "plt.yticks(range(len(feature_importance_lr)), feature_importance_lr['feature'].values)\n",
        "plt.xlabel('Average Absolute Coefficient')\n",
        "plt.title('Logistic Regression Feature Importance for Traffic Severity')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate model\n",
        "y_pred_lr = lr_model.predict(X_test_scaled)\n",
        "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "print(f\"\\nLogistic Regression Accuracy: {accuracy_lr:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_lr))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Combined Feature Importance Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalize all importance scores to 0-1 range for comparison\n",
        "def normalize_scores(scores):\n",
        "    min_val = scores.min()\n",
        "    max_val = scores.max()\n",
        "    if max_val - min_val == 0:\n",
        "        return scores\n",
        "    return (scores - min_val) / (max_val - min_val)\n",
        "\n",
        "# Combine all importance metrics\n",
        "combined_importance = pd.DataFrame({\n",
        "    'feature': X.columns,\n",
        "    'correlation': correlations.abs().values,\n",
        "    'rf_importance': feature_importance_rf['importance'].values,\n",
        "    'gb_importance': feature_importance_gb['importance'].values,\n",
        "    'lr_importance': feature_importance_lr['coefficient'].values\n",
        "})\n",
        "\n",
        "# Normalize each column\n",
        "combined_importance['correlation_norm'] = normalize_scores(combined_importance['correlation'])\n",
        "combined_importance['rf_importance_norm'] = normalize_scores(combined_importance['rf_importance'])\n",
        "combined_importance['gb_importance_norm'] = normalize_scores(combined_importance['gb_importance'])\n",
        "combined_importance['lr_importance_norm'] = normalize_scores(combined_importance['lr_importance'])\n",
        "\n",
        "# Calculate average normalized importance\n",
        "combined_importance['avg_importance'] = (\n",
        "    combined_importance['correlation_norm'] + \n",
        "    combined_importance['rf_importance_norm'] + \n",
        "    combined_importance['gb_importance_norm'] + \n",
        "    combined_importance['lr_importance_norm']\n",
        ") / 4\n",
        "\n",
        "combined_importance = combined_importance.sort_values('avg_importance', ascending=False)\n",
        "\n",
        "print(\"Combined Feature Importance Ranking:\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"{'Feature':<30} {'Avg Importance':<15} {'Correlation':<12} {'RF':<12} {'GB':<12} {'LR':<12}\")\n",
        "print(\"=\" * 80)\n",
        "for idx, row in combined_importance.iterrows():\n",
        "    print(f\"{row['feature']:<30} {row['avg_importance']:<15.4f} {row['correlation_norm']:<12.4f} \"\n",
        "          f\"{row['rf_importance_norm']:<12.4f} {row['gb_importance_norm']:<12.4f} {row['lr_importance_norm']:<12.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize combined importance\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# Top 15 features by average importance\n",
        "top_n = 15\n",
        "top_features = combined_importance.head(top_n)\n",
        "\n",
        "# Plot 1: Average Importance\n",
        "axes[0, 0].barh(range(len(top_features)), top_features['avg_importance'].values)\n",
        "axes[0, 0].set_yticks(range(len(top_features)))\n",
        "axes[0, 0].set_yticklabels(top_features['feature'].values)\n",
        "axes[0, 0].set_xlabel('Average Normalized Importance')\n",
        "axes[0, 0].set_title(f'Top {top_n} Features by Average Importance')\n",
        "axes[0, 0].invert_yaxis()\n",
        "\n",
        "# Plot 2: Comparison of all methods\n",
        "x_pos = np.arange(len(top_features))\n",
        "width = 0.2\n",
        "axes[0, 1].barh(x_pos - 1.5*width, top_features['correlation_norm'].values, width, label='Correlation')\n",
        "axes[0, 1].barh(x_pos - 0.5*width, top_features['rf_importance_norm'].values, width, label='Random Forest')\n",
        "axes[0, 1].barh(x_pos + 0.5*width, top_features['gb_importance_norm'].values, width, label='Gradient Boosting')\n",
        "axes[0, 1].barh(x_pos + 1.5*width, top_features['lr_importance_norm'].values, width, label='Logistic Regression')\n",
        "axes[0, 1].set_yticks(x_pos)\n",
        "axes[0, 1].set_yticklabels(top_features['feature'].values)\n",
        "axes[0, 1].set_xlabel('Normalized Importance')\n",
        "axes[0, 1].set_title(f'Top {top_n} Features: Method Comparison')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].invert_yaxis()\n",
        "\n",
        "# Plot 3: Heatmap of importance scores\n",
        "importance_matrix = top_features[['correlation_norm', 'rf_importance_norm', 'gb_importance_norm', 'lr_importance_norm']].T\n",
        "importance_matrix.columns = top_features['feature'].values\n",
        "sns.heatmap(importance_matrix, annot=True, fmt='.3f', cmap='YlOrRd', ax=axes[1, 0], cbar_kws={'label': 'Normalized Importance'})\n",
        "axes[1, 0].set_title(f'Top {top_n} Features: Importance Heatmap')\n",
        "axes[1, 0].set_ylabel('Method')\n",
        "axes[1, 0].set_xticklabels(axes[1, 0].get_xticklabels(), rotation=45, ha='right')\n",
        "\n",
        "# Plot 4: Summary statistics\n",
        "summary_stats = {\n",
        "    'Method': ['Correlation', 'Random Forest', 'Gradient Boosting', 'Logistic Regression'],\n",
        "    'Top Feature': [\n",
        "        combined_importance.iloc[0]['feature'],\n",
        "        feature_importance_rf.iloc[0]['feature'],\n",
        "        feature_importance_gb.iloc[0]['feature'],\n",
        "        feature_importance_lr.iloc[0]['feature']\n",
        "    ],\n",
        "    'Accuracy': [accuracy_rf, accuracy_rf, accuracy_gb, accuracy_lr]\n",
        "}\n",
        "summary_df = pd.DataFrame(summary_stats)\n",
        "axes[1, 1].axis('tight')\n",
        "axes[1, 1].axis('off')\n",
        "table = axes[1, 1].table(cellText=summary_df.values, colLabels=summary_df.columns, \n",
        "                         cellLoc='center', loc='center')\n",
        "table.auto_set_font_size(False)\n",
        "table.set_fontsize(9)\n",
        "table.scale(1.2, 1.5)\n",
        "axes[1, 1].set_title('Summary Statistics', pad=20)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Top Contributing Parameters Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display top contributing parameters\n",
        "print(\"=\" * 80)\n",
        "print(\"TOP PARAMETERS CONTRIBUTING TO TRAFFIC SEVERITY\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\nTop 10 Most Important Parameters (by average importance):\\n\")\n",
        "for i, (idx, row) in enumerate(combined_importance.head(10).iterrows(), 1):\n",
        "    print(f\"{i:2d}. {row['feature']:30s} (Avg Importance: {row['avg_importance']:.4f})\")\n",
        "    \n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"KEY INSIGHTS:\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"1. Most Important Feature: {combined_importance.iloc[0]['feature']}\")\n",
        "print(f\"2. Random Forest Top Feature: {feature_importance_rf.iloc[0]['feature']}\")\n",
        "print(f\"3. Gradient Boosting Top Feature: {feature_importance_gb.iloc[0]['feature']}\")\n",
        "print(f\"4. Highest Correlation: {correlations.abs().idxmax()} ({correlations.abs().max():.4f})\")\n",
        "print(f\"\\n5. Model Accuracies:\")\n",
        "print(f\"   - Random Forest: {accuracy_rf:.4f}\")\n",
        "print(f\"   - Gradient Boosting: {accuracy_gb:.4f}\")\n",
        "print(f\"   - Logistic Regression: {accuracy_lr:.4f}\")\n",
        "print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Detailed Analysis of Top Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze top 5 features in detail\n",
        "top_5_features = combined_importance.head(5)['feature'].tolist()\n",
        "\n",
        "fig, axes = plt.subplots(len(top_5_features), 2, figsize=(16, 4*len(top_5_features)))\n",
        "\n",
        "for idx, feature in enumerate(top_5_features):\n",
        "    # Distribution by severity\n",
        "    for severity in sorted(df['Severity'].unique()):\n",
        "        severity_data = df[df['Severity'] == severity][feature].dropna()\n",
        "        axes[idx, 0].hist(severity_data, alpha=0.6, label=f'Severity {severity}', bins=30)\n",
        "    axes[idx, 0].set_xlabel(feature)\n",
        "    axes[idx, 0].set_ylabel('Frequency')\n",
        "    axes[idx, 0].set_title(f'Distribution of {feature} by Severity')\n",
        "    axes[idx, 0].legend()\n",
        "    \n",
        "    # Box plot\n",
        "    severity_list = []\n",
        "    feature_list = []\n",
        "    for severity in sorted(df['Severity'].unique()):\n",
        "        severity_data = df[df['Severity'] == severity][feature].dropna()\n",
        "        severity_list.extend([severity] * len(severity_data))\n",
        "        feature_list.extend(severity_data.tolist())\n",
        "    \n",
        "    severity_df = pd.DataFrame({'Severity': severity_list, feature: feature_list})\n",
        "    axes[idx, 1].boxplot([severity_df[severity_df['Severity'] == s][feature].dropna() \n",
        "                          for s in sorted(df['Severity'].unique())],\n",
        "                         labels=[f'Severity {s}' for s in sorted(df['Severity'].unique())])\n",
        "    axes[idx, 1].set_ylabel(feature)\n",
        "    axes[idx, 1].set_title(f'{feature} by Severity Level')\n",
        "    axes[idx, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "This analysis has identified the key parameters that contribute most to traffic accident severity using multiple methods:\n",
        "- **Correlation Analysis**: Shows linear relationships\n",
        "- **Random Forest**: Captures non-linear relationships and feature interactions\n",
        "- **Gradient Boosting**: Emphasizes features that reduce prediction error\n",
        "- **Logistic Regression**: Provides interpretable coefficients\n",
        "\n",
        "The combined ranking provides a comprehensive view of which parameters are most important for predicting traffic severity.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
