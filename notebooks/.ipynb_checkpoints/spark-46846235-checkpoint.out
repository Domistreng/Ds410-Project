total-executor-cores=32
executor-memory=32
25/12/01 22:21:36 INFO Master: Started daemon with process name: 2526838@p-sc-2341
25/12/01 22:21:36 INFO SignalUtils: Registering signal handler for TERM
25/12/01 22:21:36 INFO SignalUtils: Registering signal handler for HUP
25/12/01 22:21:36 INFO SignalUtils: Registering signal handler for INT
25/12/01 22:21:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/12/01 22:21:37 INFO SecurityManager: Changing view acls to: dfs5910
25/12/01 22:21:37 INFO SecurityManager: Changing modify acls to: dfs5910
25/12/01 22:21:37 INFO SecurityManager: Changing view acls groups to: 
25/12/01 22:21:37 INFO SecurityManager: Changing modify acls groups to: 
25/12/01 22:21:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dfs5910); groups with view permissions: Set(); users  with modify permissions: Set(dfs5910); groups with modify permissions: Set()
25/12/01 22:21:37 INFO Utils: Successfully started service 'sparkMaster' on port 7077.
25/12/01 22:21:37 INFO Master: Starting Spark master at spark://p-sc-2341:7077
25/12/01 22:21:38 INFO Master: Running Spark version 3.3.0
25/12/01 22:21:38 INFO Utils: Successfully started service 'MasterUI' on port 8080.
25/12/01 22:21:38 INFO MasterWebUI: Bound MasterWebUI to 0.0.0.0, and started at http://p-sc-2341.2e.hpc.psu.edu:8080
25/12/01 22:21:38 INFO Master: I have been elected leader! New state: ALIVE
25/12/01 22:21:48 INFO Worker: Started daemon with process name: 1504924@p-sc-2395
25/12/01 22:21:48 INFO SignalUtils: Registering signal handler for TERM
25/12/01 22:21:48 INFO SignalUtils: Registering signal handler for HUP
25/12/01 22:21:48 INFO SignalUtils: Registering signal handler for INT
25/12/01 22:21:48 INFO Worker: Started daemon with process name: 2259641@p-sc-2389
25/12/01 22:21:48 INFO SignalUtils: Registering signal handler for TERM
25/12/01 22:21:48 INFO SignalUtils: Registering signal handler for HUP
25/12/01 22:21:48 INFO SignalUtils: Registering signal handler for INT
25/12/01 22:21:48 INFO Worker: Started daemon with process name: 2323452@p-sc-2386
25/12/01 22:21:48 INFO SignalUtils: Registering signal handler for TERM
25/12/01 22:21:48 INFO SignalUtils: Registering signal handler for HUP
25/12/01 22:21:48 INFO SignalUtils: Registering signal handler for INT
25/12/01 22:21:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/12/01 22:21:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/12/01 22:21:48 INFO Worker: Started daemon with process name: 1315470@p-sc-2346
25/12/01 22:21:48 INFO SignalUtils: Registering signal handler for TERM
25/12/01 22:21:48 INFO SignalUtils: Registering signal handler for HUP
25/12/01 22:21:48 INFO SignalUtils: Registering signal handler for INT
25/12/01 22:21:48 INFO SecurityManager: Changing view acls to: dfs5910
25/12/01 22:21:48 INFO SecurityManager: Changing modify acls to: dfs5910
25/12/01 22:21:48 INFO SecurityManager: Changing view acls groups to: 
25/12/01 22:21:48 INFO SecurityManager: Changing modify acls groups to: 
25/12/01 22:21:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dfs5910); groups with view permissions: Set(); users  with modify permissions: Set(dfs5910); groups with modify permissions: Set()
25/12/01 22:21:48 INFO SecurityManager: Changing view acls to: dfs5910
25/12/01 22:21:48 INFO SecurityManager: Changing modify acls to: dfs5910
25/12/01 22:21:48 INFO SecurityManager: Changing view acls groups to: 
25/12/01 22:21:48 INFO SecurityManager: Changing modify acls groups to: 
25/12/01 22:21:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dfs5910); groups with view permissions: Set(); users  with modify permissions: Set(dfs5910); groups with modify permissions: Set()
25/12/01 22:21:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/12/01 22:21:48 INFO SecurityManager: Changing view acls to: dfs5910
25/12/01 22:21:48 INFO SecurityManager: Changing modify acls to: dfs5910
25/12/01 22:21:48 INFO SecurityManager: Changing view acls groups to: 
25/12/01 22:21:48 INFO SecurityManager: Changing modify acls groups to: 
25/12/01 22:21:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dfs5910); groups with view permissions: Set(); users  with modify permissions: Set(dfs5910); groups with modify permissions: Set()
25/12/01 22:21:49 INFO Utils: Successfully started service 'sparkWorker' on port 41717.
25/12/01 22:21:49 INFO Utils: Successfully started service 'sparkWorker' on port 41135.
25/12/01 22:21:49 INFO Worker: Worker decommissioning not enabled.
25/12/01 22:21:49 INFO Worker: Worker decommissioning not enabled.
25/12/01 22:21:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/12/01 22:21:49 INFO Utils: Successfully started service 'sparkWorker' on port 42925.
25/12/01 22:21:49 INFO Worker: Worker decommissioning not enabled.
25/12/01 22:21:49 INFO SecurityManager: Changing view acls to: dfs5910
25/12/01 22:21:49 INFO SecurityManager: Changing modify acls to: dfs5910
25/12/01 22:21:49 INFO SecurityManager: Changing view acls groups to: 
25/12/01 22:21:49 INFO SecurityManager: Changing modify acls groups to: 
25/12/01 22:21:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dfs5910); groups with view permissions: Set(); users  with modify permissions: Set(dfs5910); groups with modify permissions: Set()
25/12/01 22:21:49 INFO Worker: Starting Spark worker 10.6.1.159:41717 with 2 cores, 63.0 GiB RAM
25/12/01 22:21:49 INFO Worker: Running Spark version 3.3.0
25/12/01 22:21:49 INFO Worker: Spark home: /storage/icds/RISE/sw8/spark-3.3.0-bin-hadoop3
25/12/01 22:21:49 INFO Worker: Starting Spark worker 10.6.1.165:41135 with 2 cores, 63.0 GiB RAM
25/12/01 22:21:49 INFO Worker: Running Spark version 3.3.0
25/12/01 22:21:49 INFO Worker: Spark home: /storage/icds/RISE/sw8/spark-3.3.0-bin-hadoop3
25/12/01 22:21:49 INFO ResourceUtils: ==============================================================
25/12/01 22:21:49 INFO ResourceUtils: No custom resources configured for spark.worker.
25/12/01 22:21:49 INFO ResourceUtils: ==============================================================
25/12/01 22:21:49 INFO Worker: Started daemon with process name: 1270476@p-sc-2372
25/12/01 22:21:49 INFO ResourceUtils: ==============================================================
25/12/01 22:21:49 INFO ResourceUtils: No custom resources configured for spark.worker.
25/12/01 22:21:49 INFO ResourceUtils: ==============================================================
25/12/01 22:21:49 INFO SignalUtils: Registering signal handler for TERM
25/12/01 22:21:49 INFO SignalUtils: Registering signal handler for HUP
25/12/01 22:21:49 INFO SignalUtils: Registering signal handler for INT
25/12/01 22:21:49 INFO Worker: Starting Spark worker 10.6.1.156:42925 with 2 cores, 63.0 GiB RAM
25/12/01 22:21:49 INFO Worker: Running Spark version 3.3.0
25/12/01 22:21:49 INFO Worker: Spark home: /storage/icds/RISE/sw8/spark-3.3.0-bin-hadoop3
25/12/01 22:21:49 INFO ResourceUtils: ==============================================================
25/12/01 22:21:49 INFO ResourceUtils: No custom resources configured for spark.worker.
25/12/01 22:21:49 INFO ResourceUtils: ==============================================================
25/12/01 22:21:49 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
25/12/01 22:21:49 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
25/12/01 22:21:49 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://p-sc-2389.2e.hpc.psu.edu:8081
25/12/01 22:21:49 INFO Worker: Connecting to master p-sc-2341:7077...
25/12/01 22:21:49 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://p-sc-2395.2e.hpc.psu.edu:8081
25/12/01 22:21:49 INFO Worker: Connecting to master p-sc-2341:7077...
25/12/01 22:21:49 INFO TransportClientFactory: Successfully created connection to p-sc-2341/10.6.1.111:7077 after 30 ms (0 ms spent in bootstraps)
25/12/01 22:21:49 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
25/12/01 22:21:49 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://p-sc-2386.2e.hpc.psu.edu:8081
25/12/01 22:21:49 INFO Worker: Connecting to master p-sc-2341:7077...
25/12/01 22:21:49 INFO TransportClientFactory: Successfully created connection to p-sc-2341/10.6.1.111:7077 after 30 ms (0 ms spent in bootstraps)
25/12/01 22:21:49 INFO Utils: Successfully started service 'sparkWorker' on port 41227.
25/12/01 22:21:49 INFO Worker: Worker decommissioning not enabled.
25/12/01 22:21:49 INFO TransportClientFactory: Successfully created connection to p-sc-2341/10.6.1.111:7077 after 27 ms (0 ms spent in bootstraps)
25/12/01 22:21:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/12/01 22:21:49 INFO Master: Registering worker 10.6.1.156:42925 with 2 cores, 63.0 GiB RAM
25/12/01 22:21:49 INFO Master: Registering worker 10.6.1.165:41135 with 2 cores, 63.0 GiB RAM
25/12/01 22:21:49 INFO Master: Registering worker 10.6.1.159:41717 with 2 cores, 63.0 GiB RAM
25/12/01 22:21:49 INFO Worker: Successfully registered with master spark://p-sc-2341:7077
25/12/01 22:21:49 INFO Worker: Successfully registered with master spark://p-sc-2341:7077
25/12/01 22:21:49 INFO Worker: Successfully registered with master spark://p-sc-2341:7077
25/12/01 22:21:49 INFO SecurityManager: Changing view acls to: dfs5910
25/12/01 22:21:49 INFO SecurityManager: Changing modify acls to: dfs5910
25/12/01 22:21:49 INFO SecurityManager: Changing view acls groups to: 
25/12/01 22:21:49 INFO SecurityManager: Changing modify acls groups to: 
25/12/01 22:21:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dfs5910); groups with view permissions: Set(); users  with modify permissions: Set(dfs5910); groups with modify permissions: Set()
25/12/01 22:21:49 INFO Worker: Starting Spark worker 10.6.1.116:41227 with 2 cores, 63.0 GiB RAM
25/12/01 22:21:49 INFO Worker: Running Spark version 3.3.0
25/12/01 22:21:49 INFO Worker: Spark home: /storage/icds/RISE/sw8/spark-3.3.0-bin-hadoop3
25/12/01 22:21:49 INFO ResourceUtils: ==============================================================
25/12/01 22:21:49 INFO ResourceUtils: No custom resources configured for spark.worker.
25/12/01 22:21:49 INFO ResourceUtils: ==============================================================
25/12/01 22:21:50 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
25/12/01 22:21:50 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://p-sc-2346.2e.hpc.psu.edu:8081
25/12/01 22:21:50 INFO Worker: Connecting to master p-sc-2341:7077...
25/12/01 22:21:50 INFO TransportClientFactory: Successfully created connection to p-sc-2341/10.6.1.111:7077 after 23 ms (0 ms spent in bootstraps)
25/12/01 22:21:50 INFO Utils: Successfully started service 'sparkWorker' on port 42957.
25/12/01 22:21:50 INFO Worker: Worker decommissioning not enabled.
25/12/01 22:21:50 INFO Master: Registering worker 10.6.1.116:41227 with 2 cores, 63.0 GiB RAM
25/12/01 22:21:50 INFO Worker: Successfully registered with master spark://p-sc-2341:7077
25/12/01 22:21:50 INFO Worker: Starting Spark worker 10.6.1.142:42957 with 2 cores, 63.0 GiB RAM
25/12/01 22:21:50 INFO Worker: Running Spark version 3.3.0
25/12/01 22:21:50 INFO Worker: Spark home: /storage/icds/RISE/sw8/spark-3.3.0-bin-hadoop3
25/12/01 22:21:50 INFO ResourceUtils: ==============================================================
25/12/01 22:21:50 INFO ResourceUtils: No custom resources configured for spark.worker.
25/12/01 22:21:50 INFO ResourceUtils: ==============================================================
25/12/01 22:21:50 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
25/12/01 22:21:50 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://p-sc-2372.2e.hpc.psu.edu:8081
25/12/01 22:21:50 INFO Worker: Connecting to master p-sc-2341:7077...
25/12/01 22:21:50 INFO TransportClientFactory: Successfully created connection to p-sc-2341/10.6.1.111:7077 after 49 ms (0 ms spent in bootstraps)
25/12/01 22:21:50 INFO Master: Registering worker 10.6.1.142:42957 with 2 cores, 63.0 GiB RAM
25/12/01 22:21:50 INFO Worker: Successfully registered with master spark://p-sc-2341:7077
25/12/01 22:21:52 INFO Worker: Started daemon with process name: 1840786@p-sc-2379
25/12/01 22:21:52 INFO SignalUtils: Registering signal handler for TERM
25/12/01 22:21:52 INFO SignalUtils: Registering signal handler for HUP
25/12/01 22:21:52 INFO SignalUtils: Registering signal handler for INT
25/12/01 22:21:52 INFO Worker: Started daemon with process name: 3255391@p-sc-2392
25/12/01 22:21:52 INFO SignalUtils: Registering signal handler for TERM
25/12/01 22:21:52 INFO SignalUtils: Registering signal handler for HUP
25/12/01 22:21:52 INFO SignalUtils: Registering signal handler for INT
25/12/01 22:21:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/12/01 22:21:53 INFO SecurityManager: Changing view acls to: dfs5910
25/12/01 22:21:53 INFO SecurityManager: Changing modify acls to: dfs5910
25/12/01 22:21:53 INFO SecurityManager: Changing view acls groups to: 
25/12/01 22:21:53 INFO SecurityManager: Changing modify acls groups to: 
25/12/01 22:21:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dfs5910); groups with view permissions: Set(); users  with modify permissions: Set(dfs5910); groups with modify permissions: Set()
25/12/01 22:21:53 INFO Utils: Successfully started service 'sparkWorker' on port 34171.
25/12/01 22:21:53 INFO Worker: Worker decommissioning not enabled.
25/12/01 22:21:54 INFO Worker: Starting Spark worker 10.6.1.149:34171 with 2 cores, 63.0 GiB RAM
25/12/01 22:21:54 INFO Worker: Running Spark version 3.3.0
25/12/01 22:21:54 INFO Worker: Spark home: /storage/icds/RISE/sw8/spark-3.3.0-bin-hadoop3
25/12/01 22:21:54 INFO ResourceUtils: ==============================================================
25/12/01 22:21:54 INFO ResourceUtils: No custom resources configured for spark.worker.
25/12/01 22:21:54 INFO ResourceUtils: ==============================================================
25/12/01 22:21:54 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
25/12/01 22:21:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/12/01 22:21:54 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://p-sc-2379.2e.hpc.psu.edu:8081
25/12/01 22:21:54 INFO Worker: Connecting to master p-sc-2341:7077...
25/12/01 22:21:54 INFO TransportClientFactory: Successfully created connection to p-sc-2341/10.6.1.111:7077 after 26 ms (0 ms spent in bootstraps)
25/12/01 22:21:54 INFO Master: Registering worker 10.6.1.149:34171 with 2 cores, 63.0 GiB RAM
25/12/01 22:21:54 INFO Worker: Successfully registered with master spark://p-sc-2341:7077
25/12/01 22:21:54 INFO SecurityManager: Changing view acls to: dfs5910
25/12/01 22:21:54 INFO SecurityManager: Changing modify acls to: dfs5910
25/12/01 22:21:54 INFO SecurityManager: Changing view acls groups to: 
25/12/01 22:21:54 INFO SecurityManager: Changing modify acls groups to: 
25/12/01 22:21:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dfs5910); groups with view permissions: Set(); users  with modify permissions: Set(dfs5910); groups with modify permissions: Set()
25/12/01 22:21:55 INFO Utils: Successfully started service 'sparkWorker' on port 45181.
25/12/01 22:21:55 INFO Worker: Worker decommissioning not enabled.
25/12/01 22:21:55 INFO Worker: Starting Spark worker 10.6.1.162:45181 with 2 cores, 63.0 GiB RAM
25/12/01 22:21:55 INFO Worker: Running Spark version 3.3.0
25/12/01 22:21:55 INFO Worker: Spark home: /storage/icds/RISE/sw8/spark-3.3.0-bin-hadoop3
25/12/01 22:21:55 INFO ResourceUtils: ==============================================================
25/12/01 22:21:55 INFO ResourceUtils: No custom resources configured for spark.worker.
25/12/01 22:21:55 INFO ResourceUtils: ==============================================================
25/12/01 22:21:56 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
25/12/01 22:21:56 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://p-sc-2392.2e.hpc.psu.edu:8081
25/12/01 22:21:56 INFO Worker: Connecting to master p-sc-2341:7077...
25/12/01 22:21:56 INFO TransportClientFactory: Successfully created connection to p-sc-2341/10.6.1.111:7077 after 29 ms (0 ms spent in bootstraps)
25/12/01 22:21:56 INFO Master: Registering worker 10.6.1.162:45181 with 2 cores, 63.0 GiB RAM
25/12/01 22:21:56 INFO Worker: Successfully registered with master spark://p-sc-2341:7077
Master URL: spark://p-sc-2341:7077
Dataset shape: (7728394, 58)

Columns: ['ID', 'Source', 'Severity', 'Start_Time', 'End_Time', 'Start_Lat', 'Start_Lng', 'End_Lat', 'End_Lng', 'Distance(mi)', 'Description', 'Street', 'City', 'County', 'State', 'Zipcode', 'Country', 'Timezone', 'Airport_Code', 'Weather_Timestamp', 'Temperature(F)', 'Wind_Chill(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Direction', 'Wind_Speed(mph)', 'Precipitation(in)', 'Weather_Condition', 'Amenity', 'Bump', 'Crossing', 'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station', 'Stop', 'Traffic_Calming', 'Traffic_Signal', 'Turning_Loop', 'Sunrise_Sunset', 'Civil_Twilight', 'Nautical_Twilight', 'Astronomical_Twilight', 'hour', 'day_of_week', 'rush_hour', 'is_weekend', 'is_clear', 'is_rainy', 'is_foggy', 'is_snowy', 'is_highway', 'is_local', 'state_encoded', 'high_accident_state']

First few rows:
Correlation with Severity (sorted by absolute value):
============================================================
is_highway                    :  0.1720
is_weekend                    :  0.0328
is_rainy                      :  0.0234
is_snowy                      :  0.0077
state_encoded                 :  0.0051
day_of_week                   : -0.0044
rush_hour                     : -0.0062
is_foggy                      : -0.0112
is_clear                      : -0.0509
high_accident_state           : -0.0657
is_local                      : -0.1565
Traceback (most recent call last):
  File "/storage/work/dfs5910/project/Ds410-Project/notebooks/graphingEngineeredFeatures.py", line 128, in <module>
    bars = axes[idx].bar(binary_severity[feature], binary_severity['mean'], 
IndexError: index 6 is out of bounds for axis 0 with size 6
25/12/01 22:24:15 INFO ShutdownHookManager: Shutdown hook called
25/12/01 22:24:15 INFO ShutdownHookManager: Deleting directory /tmp/spark-39b671a9-f0d7-45eb-bade-4f84df78b608
Execution time: 134 seconds
